{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "948FefTIxPlC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from skimage import io, transform\n",
    "from torchvision import transforms, utils\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/\"\n",
    "whole_data = pickle.load(open(\"whole_data\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=1)\n",
    "\n",
    "train_imgs = np.loadtxt(data_path + \"referit_train_imlist.txt\").astype(\"int\")\n",
    "valid_imgs = np.loadtxt(data_path + \"referit_val_imlist.txt\").astype(\"int\")\n",
    "test_imgs = np.loadtxt(data_path + \"referit_test_imlist.txt\").astype(\"int\")\n",
    "\n",
    "train_ids = np.isin(whole_data[\"img\"].values.astype(\"int\"), train_imgs)\n",
    "tr_ids = list(np.argwhere(train_ids==True))\n",
    "tr_ids = [item for sublist in tr_ids for item in sublist]\n",
    "tr_ids = np.array(tr_ids)\n",
    "all_tr_ids = tr_ids\n",
    "tr_ids = np.random.choice(tr_ids, 64000, replace = False)\n",
    "#tr_ids = np.random.choice(tr_ids, 64, replace = False)\n",
    "\n",
    "valid_ids = np.isin(whole_data[\"img\"].values.astype(\"int\"), valid_imgs)\n",
    "vld_ids = list(np.argwhere(valid_ids==True))\n",
    "vld_ids = [item for sublist in vld_ids for item in sublist]\n",
    "vld_ids = np.array(vld_ids)\n",
    "\n",
    "vld_ids = np.random.choice(vld_ids, 6400, replace = False)\n",
    "#vld_ids = np.random.choice(vld_ids, 32, replace = False)\n",
    "\n",
    "test_ids = np.isin(whole_data[\"img\"].values.astype(\"int\"), test_imgs)\n",
    "tst_ids = list(np.argwhere(test_ids==True))\n",
    "tst_ids = [item for sublist in tst_ids for item in sublist]\n",
    "tst_ids = np.array(tst_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595444"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isin(whole_data[\"img\"].values.astype(\"int\"), train_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23376325211488436"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean iou of dataset\n",
    "(whole_data.iloc[vld_ids]['IoU']-whole_data.iloc[tr_ids]['IoU'].mean()).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the model \n",
    "import model_v3dot3 as modelClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = modelClass.LocalizationDataset(data_pickle=whole_data,\n",
    "                                   data_path=data_path,\n",
    "                                   transform=transforms.Compose([\n",
    "                                               modelClass.Rescale((224,224), (224,224)),\n",
    "                                               modelClass.ToTensor()\n",
    "                                           ]))\n",
    "\n",
    "train_sampler = SubsetRandomSampler(all_tr_ids)\n",
    "valid_sampler = SubsetRandomSampler(vld_ids)\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler, num_workers=8)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21307067824787698"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_data.iloc[tr_ids]['IoU'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09504117310886573"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_data.iloc[vld_ids]['IoU'].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fr2G6p6FaDB1"
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "model = modelClass.myModel()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "load = True\n",
    "load_path = 'models/model_v3.3_full_data_iter66000.pt'\n",
    "\n",
    "if load:\n",
    "    checkpoint = torch.load(load_path)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    train_loss = checkpoint['train_loss']\n",
    "    val_loss = checkpoint['validation_loss']\n",
    "\n",
    "touch_vgg = True\n",
    "requires_grad = True\n",
    "if touch_vgg:\n",
    "    for child in model.img_feature_extractor.children():\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "\n",
    "    for child in model.box_feature_extractor.children():\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = requires_grad\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18608"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-qsKr1-0MUk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch: 5\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 10\n",
    "pr_freq = 500\n",
    "save_freq = 2000\n",
    "start_epoch = 0\n",
    "\n",
    "if load:\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "i=66000\n",
    "for epoch in range(start_epoch, max_epochs):\n",
    "    # Training\n",
    "    print('at epoch: ' + str(epoch))\n",
    "    tick_epoch = time.time()\n",
    "    tick_pr = time.time()\n",
    "    for sample in train_loader:        \n",
    "        i+=1\n",
    "        \n",
    "        image, bbox_image, loc_rel, embedding, IoU = modelClass.get_torch_data(sample)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image,bbox_image,loc_rel,embedding)\n",
    "        loss = modelClass.my_loss(outputs, IoU)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        # Validation\n",
    "        if(i%pr_freq == 0):\n",
    "            tock_pr = time.time()\n",
    "            print(str(pr_freq) + ' batch in ' + str((tock_pr-tick_pr)/60) + ' minutes')\n",
    "            with torch.set_grad_enabled(False):\n",
    "                l = []\n",
    "                for sample in validation_loader:\n",
    "                    image, bbox_image, loc_rel, embedding, IoU = modelClass.get_torch_data(sample)\n",
    "                    outputs = model(image,bbox_image,loc_rel,embedding)\n",
    "                    loss = modelClass.my_loss(outputs, IoU, margin= 0.004)\n",
    "                    l.append(loss.item())\n",
    "                val_l = np.average(l) \n",
    "                print('validation loss at iter ' + str(i) + ': ' + str(val_l))\n",
    "                val_loss.append((i,val_l))\n",
    "                print('train loss at iter ' + str(i) +': '+ str(np.average(train_loss[-pr_freq:])))\n",
    "            tick_pr = tock_pr\n",
    "        if(i%save_freq == 0):\n",
    "            torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'validation_loss': val_loss\n",
    "            }, 'models/model_v3.3_full_data_iter' + str(i) + '.pt')\n",
    "    tock_epoch = time.time()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    print('epoch in ' + str((tock_epoch - tick_epoch)/60) + ' minutes')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
